{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Лабораторная по рекомендательным системам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "JSON_DATA_PATH = \"Video_Games_5.json\"\n",
    "N = 10\n",
    "\n",
    "def iter_json_data(path):\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            yield data\n",
    "            \n",
    "def get_data_frame():\n",
    "    uid_to_id = {}\n",
    "    iid_to_id = {}\n",
    "    \n",
    "    cols = [\"uid\", \"iid\", \"review\", \"rating\", \"dt\"]\n",
    "    rows = []\n",
    "    for d in iter_json_data(JSON_DATA_PATH):\n",
    "        uid = uid_to_id.setdefault(d[\"reviewerID\"], len(uid_to_id))\n",
    "        iid = iid_to_id.setdefault(d[\"asin\"], len(iid_to_id))\n",
    "        review = d[\"reviewText\"]\n",
    "        rating = float(d[\"overall\"])\n",
    "        dt = int(d[\"unixReviewTime\"])\n",
    "        rows.append((uid, iid, review, rating, dt))\n",
    "        \n",
    "    return pd.DataFrame(rows, columns=cols)\n",
    "\n",
    "def split_df_by_dt(df, p=0.8):\n",
    "    \"\"\"Функция разбивает df на тестовую и тренировочную выборки по времени \n",
    "    публикации отзывов (значение времени в поле dt)\n",
    "    \n",
    "    :param p: персентиль значений dt, которые образуют тренировочную выборку. Например p=0.8 означает, что в \n",
    "    тренировочной части будут отзывы, соответствующие первым 80% временного интервала \n",
    "    :return: два pd.DataFrame объекта\n",
    "    \"\"\"\n",
    "    border_dt = df.dt.quantile(p)\n",
    "    print(\"Min=%s, border=%s, max=%s\" % (df.dt.min(), border_dt, df.dt.max()))\n",
    "    training_df, test_df  = df[df.dt <= border_dt], df[df.dt > border_dt]\n",
    "    print(\"Размер до очистки:\", training_df.shape, test_df.shape)\n",
    "    # удаляем из тестовых данных строки, соответствующие пользователям или объектам, \n",
    "    # которых нет в тренировочных данных \n",
    "    # (пользователи - избегаем проблем для персональных систем, объекты - для всех)\n",
    "    test_df = test_df[test_df.uid.isin(training_df.uid) & test_df.iid.isin(training_df.iid)]\n",
    "    print(\"Размер после очистки:\", training_df.shape, test_df.shape)\n",
    "    return training_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Installing the game was a struggle (because of...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1341792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>If you like rally cars get this game you will ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1372550400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1st shipment received a book instead of the ga...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1403913600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>I got this version instead of the PS3 version,...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1315958400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I had Dirt 2 on Xbox 360 and it was an okay ga...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1308009600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid  iid                                             review  rating  \\\n",
       "0    0    0  Installing the game was a struggle (because of...     1.0   \n",
       "1    1    0  If you like rally cars get this game you will ...     4.0   \n",
       "2    2    0  1st shipment received a book instead of the ga...     1.0   \n",
       "3    3    0  I got this version instead of the PS3 version,...     3.0   \n",
       "4    4    0  I had Dirt 2 on Xbox 360 and it was an okay ga...     4.0   \n",
       "\n",
       "           dt  \n",
       "0  1341792000  \n",
       "1  1372550400  \n",
       "2  1403913600  \n",
       "3  1315958400  \n",
       "4  1308009600  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data_frame()\n",
    "\n",
    "# uid - идентификатор пользователя\n",
    "# iid - идентификатор объекта\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделеяем данные на тренировочные и тестовые."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min=939859200, border=1377129600.0, max=1405987200\n",
      "Размер до очистки: (185427, 5) (46353, 5)\n",
      "Размер после очистки: (185427, 5) (19174, 5)\n"
     ]
    }
   ],
   "source": [
    "training_df, test_df = split_df_by_dt(df)\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Метрика качества и базовый класс модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки качества системы воспользуемся метрикой `hit-ratio (HR)`. \n",
    "\n",
    "$$\n",
    "HR = \\frac{1}{|U_T|}\\sum_{u \\in U_T} \\mathrm{I}(Rel_u \\cap Rec_u)\n",
    "$$\n",
    "\n",
    "* $U_T$ - множество пользователей из тестовой выборки\n",
    "* $Rec_u$ - множество объектов, рекомендованных пользователю $u$ \n",
    "* $Rel_u$ - множество объектов, оцененных пользователем $u$ в тестовой выборке\n",
    "* $\\mathrm{I}(Rel_u \\cap Rec_u)$ - бинарная функция-индикатор. Функция возвращает 1 если $Rel_u \\cap Rec_u \\ne \\emptyset$, иначе 0\n",
    "\n",
    "$HR=1$ если для каждого пользователя мы рекомендовали хотя бы один релевантный объект. Так как обычно пользователи просматривают только первые $N$ рекомендаций, мы будем считать метрику $HR@N$, где $N=10$ (т.е. множество $Rec_u$ будет содержать только 10 объектов). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hit_ratio(recs_dict, test_dict):\n",
    "    \"\"\"Функция считает метрику hit-ration для двух словарей\n",
    "    :recs_dict: словарь рекомендаций типа {uid: {iid: score, ...}, ...}\n",
    "    :test_dict: тестовый словарь типа {uid: {iid: score, ...}, ...}\n",
    "    \"\"\"\n",
    "    hits = 0\n",
    "    for uid in test_dict:\n",
    "        if set(test_dict[uid].keys()).intersection(recs_dict.get(uid, {})):\n",
    "            hits += 1\n",
    "    return hits / len(test_dict)\n",
    "\n",
    "def get_test_dict(test_df):\n",
    "    \"\"\"Функция, конвертирующая тестовый df в словарь\n",
    "    \"\"\"\n",
    "    test_dict = {}\n",
    "    for t in test_df.itertuples():\n",
    "        test_dict.setdefault(t.uid, {})\n",
    "        test_dict[t.uid][t.iid] = t.rating\n",
    "    return test_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем тестовый набор в словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dict = get_test_dict(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим базовые классы для рекомендателей, которые можно использовать при построении собственных моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BasicRecommender(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_recs(self, uid, top):\n",
    "        \"\"\"Строит рекомендации для пользователя uid\n",
    "        :return: словарь типа {iid: score, ...}\n",
    "        \"\"\"\n",
    "        return {}\n",
    "    \n",
    "    def get_batch_recs(self, uids, top):\n",
    "        \"\"\"Строит рекомендации для нескольких пользователей uids\n",
    "        :return: словарь типа {uid: {iid: score, ...}, ...}\n",
    "        \"\"\"\n",
    "        return {uid: self.get_recs(uid, top) for uid in uids}\n",
    "    \n",
    "class NonPersRecommender(BasicRecommender):\n",
    "    def __init__(self, df):\n",
    "        super(NonPersRecommender, self).__init__()\n",
    "        self.recs = self._prepare_recs(df)\n",
    "        \n",
    "    def _prepare_recs(self, df):\n",
    "        return pd.Series([])\n",
    "    \n",
    "    def get_recs(self, uid, top):\n",
    "        return self.recs[:top].to_dict()\n",
    "    \n",
    "    def get_batch_recs(self, uids, top):\n",
    "        non_pers_recs = self.get_recs(None, top)\n",
    "        return {uid: non_pers_recs for uid in uids}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Non-personalized RS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Неперсонализированная рекомендательная система - рекомендации для одного пользователя строятся на основе отзывов, оставленных всеми пользователями.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. RS, рекомендующая наиболее популярный контент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MostReviewedRS(NonPersRecommender):\n",
    "    def _prepare_recs(self, df):\n",
    "        # считаем количество отзывов для каждого объекта (pandas сортирует их по убыванию)\n",
    "        return df.iid.value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03961848862802641"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MostReviewedRS(training_df)\n",
    "recs = model.get_batch_recs(test_df['uid'], N)\n",
    "\n",
    "hit_ratio(recs, test_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. RS, рекомендующая наиболее контент c наибольшим средним рейтингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HighestRatingRS(NonPersRecommender):\n",
    "    def _prepare_recs(self, df):\n",
    "        return df.groupby('iid').rating.mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001467351430667645"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HighestRatingRS(training_df)\n",
    "recs = model.get_batch_recs(test_df['uid'], N)\n",
    "\n",
    "hit_ratio(recs, test_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. RS, рекомендующая популярный контент на основе последних обзоров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TrendyRS(NonPersRecommender):\n",
    "    def __init__(self, df, recsN):\n",
    "        super(NonPersRecommender, self).__init__()\n",
    "        self.recs = self._prepare_recs(df, recsN)\n",
    "        \n",
    "    def _prepare_recs(self, df, recsN):\n",
    "        return df.sort_values('dt')[-recsN:].iid.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рекомендация на оcнове **последних 10000** обзоров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09655172413793103"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TrendyRS(training_df, 10000)\n",
    "recs = model.get_batch_recs(test_df['uid'], N)\n",
    "\n",
    "hit_ratio(recs, test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TrendyRS_days(NonPersRecommender):\n",
    "    def __init__(self, df, daysN):\n",
    "        super(NonPersRecommender, self).__init__()\n",
    "        self.recs = self._prepare_recs(df, daysN)\n",
    "        \n",
    "    def _prepare_recs(self, df, daysN):\n",
    "        return df.sort_values('dt')[df['dt'] >= int(df.iloc[-1:].dt - daysN*86400)].iid.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рекомендация на оcнове обзоров за **последние 100 дней** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Skaarj\\Documents\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10359501100513573"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TrendyRS_days(training_df, 100)\n",
    "recs = model.get_batch_recs(test_df['uid'], N)\n",
    "\n",
    "hit_ratio(recs, test_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшая оценка для неперсонализированной RS - **0.10359501100513573**, модель на основе самых популярных отзывов за последние 100 дней."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Content-based RS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рекомендации строятся путем поиска объектов, чьи вектора похожи на вектор предпочтений пользователя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Векторизация описания игр"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализуем все описания: исключим стоп-слова, приведем к нижнему регистру, выделим леммы и т.п."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list = stopword_list + ['game', 'games']\n",
    "x = re.compile('[%s]' % re.escape(string.punctuation + string.digits))\n",
    "pst = PorterStemmer()\n",
    "wlem = WordNetLemmatizer()\n",
    "\n",
    "tokenized_docs = [word_tokenize(doc) for doc in training_df.loc[:,'review']]\n",
    "normalized_docs = []\n",
    "\n",
    "for review in tokenized_docs:\n",
    "    #new_review = []\n",
    "    new_review = ''\n",
    "    for token in review:\n",
    "        token = token.lower()\n",
    "        \n",
    "        new_token = x.sub(u'', token)\n",
    "        if (not new_token == u'') and (new_token not in stopword_list) and (len(new_token) > 2) and (len(new_token) < 21):\n",
    "            #new_review.append(wlem.lemmatize(pst.stem(new_token)))\n",
    "            new_review += wlem.lemmatize(pst.stem(new_token)) + ' '\n",
    "            \n",
    "    normalized_docs.append(new_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>dt</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Installing the game was a struggle (because of...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1341792000</td>\n",
       "      <td>instal struggl window live bug championship ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>If you like rally cars get this game you will ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1372550400</td>\n",
       "      <td>like ralli car get funit orient european marke...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid  iid                                             review  rating  \\\n",
       "0    0    0  Installing the game was a struggle (because of...     1.0   \n",
       "1    1    0  If you like rally cars get this game you will ...     4.0   \n",
       "\n",
       "           dt                                         normalized  \n",
       "0  1341792000  instal struggl window live bug championship ra...  \n",
       "1  1372550400  like ralli car get funit orient european marke...  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df[\"normalized\"] = normalized_docs\n",
    "training_df.loc[:1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим TF-IDF на нормализованных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf.fit(training_df.loc[:,'normalized'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составим коллекцию векторов всех игр из отзывов, выбросив игры у которых меньше 5 отзывов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "iids = training_df.groupby('iid').uid.count()\n",
    "iids = iids[iids > 5].reset_index()\n",
    "iids.columns=['iid', 'num']\n",
    "\n",
    "X_g = []\n",
    "\n",
    "for iid in iids.iid:\n",
    "    tmp = tfidf.transform(training_df.loc[training_df.iid==iid].normalized)\n",
    "    tmp = csr_matrix(tmp.sum(axis=0))\n",
    "    X_g.append(tmp)\n",
    "    \n",
    "X_g = vstack(X_g, 'csr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4.2. Создание профилей пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uids = test_df.uid.unique()\n",
    "\n",
    "X_u = []\n",
    "\n",
    "for uid in uids:\n",
    "   \n",
    "    u_mean_rating = training_df.loc[training_df.uid == uid].rating.mean()\n",
    "    u_iids = training_df.loc[training_df.uid == uid].iid.unique()\n",
    "    \n",
    "    u_profile = []\n",
    "\n",
    "    for iid in u_iids:\n",
    "        rating = training_df.loc[(training_df.uid == uid) & (training_df.iid == iid)].rating.values[0] - u_mean_rating\n",
    "        \n",
    "        tmp = tfidf.transform(training_df.loc[training_df.iid==iid].normalized) * rating\n",
    "        tmp = csr_matrix(tmp.sum(axis=0))\n",
    "        u_profile.append(tmp)\n",
    "\n",
    "    u_profile = vstack(u_profile, 'csr')\n",
    "    \n",
    "    X_u.append(csr_matrix(u_profile.sum(axis=0)))\n",
    "\n",
    "X_u = vstack(X_u, 'csr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Построение рекомендаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ContRS_cosine(BasicRecommender):\n",
    "    def __init__(self, df_i, df_u, x_i, x_u):\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        self.items = df_i\n",
    "        self.users = df_u\n",
    "        self.X_items = x_i\n",
    "        self.X_users = x_u\n",
    "        super(ContRS_cosine, self).__init__()\n",
    "    \n",
    "    def get_recs(self, uid, top):\n",
    "        x_uid = np.where(uids == uid)\n",
    "        \n",
    "        sims = cosine_similarity(self.X_users[x_uid], self.X_items)\n",
    "        best_iid = np.argsort(sims[0])[-(top+1):-1]\n",
    "        true_x_iid = [iids.ix[x_iid,'iid'] for x_iid in best_iid]\n",
    "               \n",
    "        return dict(zip(true_x_iid, sims[0, best_iid]))\n",
    "    \n",
    "    def get_batch_recs(self, top):\n",
    "        return {uid: self.get_recs(uid, top) for uid in self.users[0:20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = {}\n",
    "\n",
    "for x_u in range(0,X_u.shape[0]):\n",
    "    sims = cosine_similarity(X_u[x_u], X_g)\n",
    "    \n",
    "    best_iid = np.argsort(sims[0])[-(10+1):-1]\n",
    "    true_x_iid = [iids.ix[x_iid,'iid'] for x_iid in best_iid]\n",
    "    \n",
    "    recs[np.str(uids[x_u])] = dict(zip(true_x_iid, sims[0, best_iid]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hit_ratio(recs, test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0019075568598679383"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ContRS_cosine(iids, uids, X_g, X_u)\n",
    "recs = model.get_batch_recs(N)\n",
    "\n",
    "hit_ratio(recs, test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "sims = cosine_similarity(X_u[0], X_g)\n",
    "\n",
    "best_iid = np.argsort(sims[0])[-(10+1):-1]\n",
    "true_x_iid = [iids.ix[x_iid,'iid'] for x_iid in best_iid]\n",
    "\n",
    "recs_u0 = dict(zip(true_x_iid, sims[0, best_iid]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_iid = iids.ix[6142,'iid']\n",
    "\n",
    "item_profile = tfidf.transform(training_df.loc[training_df.iid==true_iid].normalized)\n",
    "\n",
    "ftr_id_to_term = {ftr_id: term for term, ftr_id in tfidf.vocabulary_.items()}\n",
    "\n",
    "for ftr_id, score in sorted(zip(item_profile.indices, item_profile.data), key=lambda x: x[1], reverse=True):\n",
    "    print(ftr_id_to_term[ftr_id], \":\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_uid = uids[0]\n",
    "\n",
    "u_mean_rating = training_df.loc[training_df.uid == true_uid].rating.mean()\n",
    "u_iids = training_df.loc[training_df.uid == true_uid].iid.unique()\n",
    "\n",
    "u_profile = []\n",
    "\n",
    "for iid in u_iids:\n",
    "    rating = training_df.loc[(training_df.uid == true_uid) & (training_df.iid == iid)].rating.values[0] - u_mean_rating\n",
    "\n",
    "    tmp = tfidf.transform(training_df.loc[training_df.iid==iid].normalized) * rating\n",
    "    tmp = csr_matrix(tmp.sum(axis=0))\n",
    "    u_profile.append(tmp)\n",
    "\n",
    "u_profile = vstack(u_profile, 'csr')\n",
    "\n",
    "ftr_id_to_term = {ftr_id: term for term, ftr_id in tfidf.vocabulary_.items()}\n",
    "\n",
    "for ftr_id, score in sorted(zip(u_profile.indices, u_profile.data), key=lambda x: x[1], reverse=True):\n",
    "    print(ftr_id_to_term[ftr_id], \":\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Item-based collaborative filtering RS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
